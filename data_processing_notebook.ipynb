{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "model_id = \"anton-l/xtreme_s_xlsr_300m_minds14\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Idx  Label                 Path\n",
      "0    audio_876      2  train/audio_876.wav\n",
      "1    audio_208      4  train/audio_208.wav\n",
      "2    audio_408      3  train/audio_408.wav\n",
      "3    audio_772      2  train/audio_772.wav\n",
      "4    audio_356      2  train/audio_356.wav\n",
      "..         ...    ...                  ...\n",
      "695  audio_525      2  train/audio_525.wav\n",
      "696  audio_291      2  train/audio_291.wav\n",
      "697  audio_305      2  train/audio_305.wav\n",
      "698  audio_524      2  train/audio_524.wav\n",
      "699  audio_194      3  train/audio_194.wav\n",
      "\n",
      "[700 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'C:/Users/bruno/OneDrive - Imperial College London/Pers/Portfolio/Sound Classifier/nuwehack-data-AI_SR/data/labels_paths_train.csv'\n",
    "df = load_data(csv_file_path)\n",
    "\n",
    "# To see the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    data = []\n",
    "    base_directory = \"C:/Users/bruno/OneDrive - Imperial College London/Pers/Portfolio/Sound Classifier/nuwehack-data-AI_SR/data/\"\n",
    "    for index, row in df.iterrows():\n",
    "        file_path = os.path.join(base_directory, row['Path'])\n",
    "        audio_array, _ = librosa.load(file_path, sr=None)  # Preserve the original sampling rate\n",
    "        \n",
    "        # Structure the data\n",
    "        item = {\n",
    "            \"file\": file_path,\n",
    "            \"audio\": {\n",
    "                \"path\": file_path,\n",
    "                \"array\": audio_array,\n",
    "                \"sampling_rate\": sampling_rate,\n",
    "            },\n",
    "            \"label\": row['Label'],  # Using 'Label' as the genre/classification label\n",
    "        }\n",
    "        data.append(item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': 'C:/Users/bruno/OneDrive - Imperial College London/Pers/Portfolio/Sound Classifier/nuwehack-data-AI_SR/data/train/audio_876.wav', 'audio': {'path': 'C:/Users/bruno/OneDrive - Imperial College London/Pers/Portfolio/Sound Classifier/nuwehack-data-AI_SR/data/train/audio_876.wav', 'array': array([-0.02017212, -0.00720215, -0.01403809, ..., -0.0194397 ,\n",
      "       -0.01556396, -0.009552  ], dtype=float32), 'sampling_rate': 16000}, 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -6.52e-09, Variance: 1.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sampling_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sample \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Variance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mvar(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m inputs \u001b[38;5;241m=\u001b[39m feature_extractor(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Variance: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mvar(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\feature_extraction_utils.py:86\u001b[0m, in \u001b[0;36mBatchFeature.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03mIf the key is a string, returns the value of the dict associated to `key` ('input_values', 'attention_mask',\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03metc.).\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with integers is not available when using Python based feature extractors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sampling_rate'"
     ]
    }
   ],
   "source": [
    "\n",
    "sample = data[0][\"audio\"]\n",
    "print(f\"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}\")\n",
    "inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "print(f\"inputs keys: {list(inputs.keys())}\")\n",
    "print(\n",
    "    f\"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data:\n",
    "    sample = item[\"audio\"]\n",
    "    \n",
    "    # Process the audio sample through the feature extractor\n",
    "    inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "    \n",
    "    # Normalize the 'input_values'\n",
    "    normalized_input_values = (inputs['input_values'] - np.mean(inputs['input_values'])) / np.sqrt(np.var(inputs['input_values']))\n",
    "    \n",
    "    # Option 1: Replace the original 'input_values' with the normalized ones\n",
    "    inputs['array'] = normalized_input_values\n",
    "    \n",
    "    # Option 2: Add the normalized 'input_values' as a new key to the 'audio' dictionary\n",
    "    # sample['normalized_input_values'] = normalized_input_values\n",
    "    \n",
    "    # Update the item with the new inputs (choose depending on whether you used option 1 or 2)\n",
    "    item[\"audio\"] = inputs  # If you're updating the inputs directly\n",
    "    # item[\"audio\"] = sample  # If you're updating the sample with a new key for normalized values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': 'C:/Users/bruno/OneDrive - Imperial College London/Pers/Portfolio/Sound Classifier/nuwehack-data-AI_SR/data/train/audio_876.wav',\n",
       " 'audio': {'input_values': [array([-0.95584095, -0.341237  , -0.6651694 , ..., -0.92113394,\n",
       "        -0.73747575, -0.45258877], dtype=float32)], 'attention_mask': [array([1, 1, 1, ..., 1, 1, 1])], 'array': array([[-0.95594823, -0.3412753 , -0.6652441 , ..., -0.92123735,\n",
       "         -0.73755854, -0.45263958]], dtype=float32)},\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, output_file):\n",
    "    # TODO: Save processed data to a CSV file\n",
    "    # I don't need to do this for now\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_file = 'C:/Users/bruno/OneDrive - Imperial College London/Pers/Portfolio/Sound Classifier/nuwehack-data-AI_SR/data/transformed_data.csv'\n",
    "save_data(data, output_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='Data processing script for Automated Instrument Sound Recognition Hackathon')\n",
    "    parser.add_argument(\n",
    "        '--input_file',\n",
    "        type=str,\n",
    "        default='data/labels_paths_train.csv',\n",
    "        help='Path to the raw data file to process'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output_file', \n",
    "        type=str, \n",
    "        default='data/processed_data/', \n",
    "        help='Folder path to save the processed data'\n",
    "    )\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input_file INPUT_FILE]\n",
      "                             [--output_file OUTPUT_FILE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\bruno\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-1476Y5X4owonEewQ.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(input_file, output_file):\n",
    "    df = load_data(input_file)\n",
    "    df_clean = clean_data(df)\n",
    "    df_processed = preprocess_data(df_clean)\n",
    "    save_data(df_processed, output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_arguments()\n",
    "    main(args.input_file, args.output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
